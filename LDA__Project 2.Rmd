---
title: "LDA_Project2"
author: "Sai Sreyaa Krishna Mallemala"
date: "2025-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggformula)
library(tidyverse)
library(tidymodels)
library(gridExtra)
library(readxl)
library(discrim)
library(yardstick)
```

# Data Loading and Preprocessing

```{r}
# Load and preprocess the data
df_2019 <- read_excel("pfi-data.xlsx", sheet = "curated 2019")
```

# Standardizing ALLGRADEX for 2019 data

```{r}
df_2019 <- df_2019 %>%
  mutate(
    ALLGRADEX_2019raw = ALLGRADEX,
    ALLGRADEX_std = case_when(
      ALLGRADEX %in% c(2, 3) ~ 0,                       # both K flavors → Kindergarten
      ALLGRADEX >= 4 & ALLGRADEX <= 15 ~ ALLGRADEX - 3, # 1st–12th → 1–12
      TRUE ~ NA_real_
    )
  )
```

# Filtering for high school students only

```{r}
df <- df_2019 %>%
  filter(ALLGRADEX_std >= 6 & ALLGRADEX_std <= 12)
```

# Handling target variable classes and missing values

```{r}
df <- df %>%
  # turn -1 and 5 into NA
  mutate(SEGRADES = na_if(SEGRADES, -1),
         SEGRADES = na_if(SEGRADES, 5)) %>%

  # drop rows where SEGRADES is missing
  filter(!is.na(SEGRADES)) %>%

  # create binary target: high vs low
  mutate(
    success = case_when(
      SEGRADES %in% c(1, 2) ~ "high",
      SEGRADES %in% c(3, 4) ~ "low"
    ),
    success = factor(success, levels = c("low", "high"))
  )%>%
  drop_na(success)

df %>% count(success)

```
```{r}
levels(df$success)
```

# Removing all unnecessary variables

```{r}
df <- df %>%
  select(-ZIPLOCL, -CDOBMM, -CDOBYY, -BASMID, -ALLGRADEX_std, -MOSTIMPT, -INTNUM, -ALLGRADEX_2019raw, -ALLGRADEX, -SEGRADES, - HHPARN19_BRD)
```

```{r}
glimpse(df)
```

# Choosing predictors for LDA

We are using these predictors as they make sense for grades:

HHPARN19X – number of parents in the household
EDCPUB – public vs other
SCCHOICE – school choice
EINTNET – internet at home
SCHLHRSWK – school hours per week
PARGRADEX – parent education
NUMSIBSX – number of siblings

```{r}
predictor_variables <- c(
  "HHPARN19X",  # number of parents in household
  "EDCPUB",     # public vs other school
  "SCCHOICE",   # school choice
  "EINTNET",    # internet at home
  "SCHLHRSWK",  # school hours per week
  "PARGRADEX",  # parent education
  "NUMSIBSX"    # number of siblings
)
```


```{r}
df_model <- df %>%
select(success, all_of(predictor_variables))
```

This step updates the dataset to keep only the response variable success along
with the seven predictors that will be used in the LDA model. These predictors
are for family structure, school type, school choice, internet access, school
hours, parent education, and number of siblings.

# Checking whether all variables are numeric

```{r}
df_model %>% 
  summarise(across(all_of(predictor_variables), ~ class(.)))
```

# Test-Train Data

```{r}
set.seed(123)

data_split <- initial_split(df_model, prop = 0.8, strata = success)
train_data <- training(data_split)
test_data  <- testing(data_split)
nrow(train_data)
nrow(test_data)
```

Stratified sampling based on the success variable is used to divide the data into
an 80% training set and a 20% test set, preserving the same proportion of low and
high success cases in both sets. This results in 7,472 observations for the training
set and 1,869 observations for the test set. We train the LDA model on the training
portion and evaluate the performance of the model using the test portion.

```{r}
prop_low  <- mean(train_data$success == "low")
prop_high <- mean(train_data$success == "high")

prop_low
prop_high
```


# Fitting the LDA Model

```{r}
lda_model <- discrim_linear() %>%
  set_mode("classification") %>%
  set_engine("MASS", prior = c(low = prop_low, high = prop_high)) %>%
  fit(
    success ~ HHPARN19X + EDCPUB + SCCHOICE +
      EINTNET + SCHLHRSWK + PARGRADEX + NUMSIBSX,
    data = train_data
  )

lda_model
```

The LDA model is estimated using the MASS engine with class priors set to the 
observed proportions in the training data-about 13.22% of students are in the 
low-success group, and 86.78% of students are in the high-success group. Using 
these empirical priors informs the model to expect high success much more often 
than low success and incorporates the class imbalance directly into the discriminant
rule. The output first reports these prior probabilities and then reports the 
group means for each predictor in the lowand high-success categories. For instance,
students classified as in the lowsuccess group have averages such as HHPARN19X = 1.786,
EINTNET = 3.872, SCHLHRSWK = 3.688, and PARGRADEX = 3.126, while for students 
classified as being in the high-success group, these averages are slightly 
higher-EINTNET = 3.910, SCHLHRSWK = 3.776, PARGRADEX = 3.676. These patterns 
summarize how family and school-related variables differ across lower versus 
higher performing students.

The coefficients of the linear discriminant show the contribution that each predictor 
makes toward separating the two groups along the LD1 dimension. In particular, 
negative coefficients, for example HHPARN19X (−0.705) and SCCHOICE (−0.590), 
pull predictions toward the low-success category, while positive coefficients 
such as EDCPUB (0.681), EINTNET (0.310), SCHLHRSWK (0.128) and PARGRADEX (0.467)
pull the predictions toward the high-success category. Such coefficients show both
the direction and strength of each variable's influence in forming the discriminant 
function that captures the differentiation of low- versus high-success students.

# Getting predictions on test data 

```{r}
lda_test <- augment(lda_model, new_data = test_data)
head(lda_test)
```


```{r}
conf_mat(lda_test, truth = success, estimate = .pred_class)
```

```{r}
library(ggplot2)
library(dplyr)

cm <- conf_mat(lda_test, truth = success, estimate = .pred_class)

cm_df <- as.data.frame(cm$table)

ggplot(cm_df, aes(x = Prediction, y = Truth, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "white", size = 6) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Confusion Matrix Heatmap") +
  theme_minimal()
```




```{r}
metrics <- bind_rows(
  accuracy(lda_test, truth = success, estimate = .pred_class),
  precision(lda_test, truth = success, estimate = .pred_class, event_level = "first"),
  recall(lda_test, truth = success, estimate = .pred_class, event_level = "first"),
  f_meas(lda_test, truth = success, estimate = .pred_class, event_level = "first"),
  roc_auc(lda_test, truth = success, .pred_low)
)

metrics
```
It can be seen from the confusion matrix that, out of 1,869 test observations,
the model correctly classified 1,614 students with an overall accuracy of 86.36%.
Most correct predictions fall in the high-success category, where it rightly
identified 1,613 high-success cases and only 9 were misclassified as low success.
In contrast, performance on the low-success group is abysmal: out of 247 true 
low-success students, the model correctly identified only 1, while 246 were 
mispredicted as being high success. This then results in very weak evaluation 
metrics for the class of interest that includes precision of 0.10, recall of 0.004,
and F1-score of 0.008, again showing the model completely fails to identify 
low-performing students. A ROC AUC value of 0.67 suggests that the ranking ability
remains moderate but still limited in distinguishing between low and high success.
Overall, the model is performing strongly in identifying high-success students but
very poorly in low-success students, which is exactly the target group of interest.

```{r}
library(dplyr)
library(ggplot2)

# 1. Getting the underlying MASS::lda object from the parsnip model
lda_engine <- lda_model$fit

# 2. Predicting discriminant scores on the test data
lda_scores <- predict(lda_engine, newdata = test_data)

# 3. Add LD1 (first discriminant) as a new column to test_data
lda_values <- test_data %>%
  mutate(LD1 = lda_scores$x[, 1])

# 4. Plot LD1 distribution by success group
ggplot(lda_values, aes(x = LD1, fill = success)) +
  geom_density(alpha = 0.4) +
  labs(
    title = "LD1 Distribution by Success Group",
    x = "Linear Discriminant (LD1)",
    fill = "Success"
  ) +
  theme_minimal()

```
The LD1 density plot shows how the LDA model has separated students who fall into
the low-grade category, grades 3-4, and the high-grade category, grades 1-2, using
the first linear discriminant. The two curves are heavily overlapping, which 
suggests that LD1 does not strongly separate the lower grade students from the 
higher grade students. While the high-grade group shifts slightly to the right,
and the low-grade group shifts slightly to the left, the strong overlap indicates
a lack of strong separation by the predictors. This aligns with the overall 
performance of the model, where LDA failed to accurately identify the low-grade students.

```{r}
library(ggplot2)

# ROC curve data
roc_data <- roc_curve(lda_test, truth = success, .pred_low)


ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color="darkgreen", size=1.2) +
geom_abline(linetype="dashed", color="red") +
labs(title="ROC Curve for LOW Success Detection",
x="False Positive Rate",
y="True Positive Rate") +
theme_minimal()

```

The ROC curve presents the capability of the LDA model in identifying low-success
(3-4 grade) students using the predicted probability .pred_low. 
It lies only a little above the diagonal dashed baseline, indicating that the model
has weak discrimination capability to identify low-success from high-success students.
As the false-positive rate increases, the true-positive rate (correctly identifying low grades)
increases only gradually, further indicating its inability to distinguish between 
the two grade groups. The AUC is about 0.67, which means the model has only 
moderate ranking ability. That is, it is better than random guessing but is not 
reliable in detecting the low-grade students. Overall, the findings from the ROC
reinforce the previous two: the LDA model is much better at identifying high grades
than low grades, which is actually the group of primary interest.


# Final Conclusion

Based on the final LDA model fitted with priors that match the training-set 
proportions-about 13% low success and 87% high success-the model performs well 
in identifying high-success students but badly in finding the low-success students,
which was the main focus of this project. Here, from 1,869 test observations, the
model classifies 1,614 correctly, giving an overall accuracy of 86.36%. However,
almost all correct predictions come from the high-success category. The model 
identifies 1,613 high-success students correctly and misclassifies just 9 high-success
students into the low-success category. On the other hand, this model thoroughly
fails to find the low-success students. From 247 actual low-success students, 
the LDA model could detect only 1, while misclassifying 246 into the category 
of high success. This gives extremely weak evaluation metrics for the 
low-success class: precision = 0.10, recall = 0.004, F1-score = 0.008, 
all indicating near-zero ability to identify the low-performing group. 
The ROC curve for a low-success class provides an AUC of 0.67, giving only moderate
ranking ability and weak separation between low and high success. The LD1 density
plot also points to the same conclusion: there is heavy overlap between the 
distributions of low- and high-success students, implying that predictors 
do not create any definite boundary between the two categories. 
In summary, whereas the LDA model is very effective in recognizing the high-success students,
it is defective in identifying the low-success students and, consequently, 
the primary target of the analysis. This signifies that the present predictors 
and model structure do not provide meaningful signal for detecting low academic performance.