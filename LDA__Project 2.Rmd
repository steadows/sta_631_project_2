---
title: "LDA_Project2"
author: "Sai Sreyaa Krishna Mallemala"
date: "2025-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggformula)
library(tidyverse)
library(tidymodels)
library(gridExtra)
library(readxl)
library(discrim)
library(yardstick)
```

# Data Loading and Preprocessing

```{r}
# Load and preprocess the data
df_2019 <- read_excel("pfi-data.xlsx", sheet = "curated 2019")
```

# Standardizing ALLGRADEX for 2019 data

```{r}
df_2019 <- df_2019 %>%
  mutate(
    ALLGRADEX_2019raw = ALLGRADEX,
    ALLGRADEX_std = case_when(
      ALLGRADEX %in% c(2, 3) ~ 0,                       # both K flavors → Kindergarten
      ALLGRADEX >= 4 & ALLGRADEX <= 15 ~ ALLGRADEX - 3, # 1st–12th → 1–12
      TRUE ~ NA_real_
    )
  )
```

# Filtering for high school students only

```{r}
df <- df_2019 %>%
  filter(ALLGRADEX_std >= 6 & ALLGRADEX_std <= 12)
```

# Handling target variable classes and missing values

```{r}
df <- df %>%
  # turn -1 and 5 into NA
  mutate(SEGRADES = na_if(SEGRADES, -1),
         SEGRADES = na_if(SEGRADES, 5)) %>%

  # drop rows where SEGRADES is missing
  filter(!is.na(SEGRADES)) %>%

  # create binary target: high vs low
  mutate(
    success = case_when(
      SEGRADES %in% c(1, 2) ~ "high",
      SEGRADES %in% c(3, 4) ~ "low"
    ),
    success = factor(success, levels = c("low", "high"))
  )%>%
  drop_na(success)

df %>% count(success)

```

# Removing all unnecessary variables

```{r}
df <- df %>%
  select(-ZIPLOCL, -CDOBMM, -CDOBYY, -BASMID, -ALLGRADEX_std, -MOSTIMPT, -INTNUM, -ALLGRADEX_2019raw, -ALLGRADEX, -SEGRADES, - HHPARN19_BRD)
```

```{r}
glimpse(df)
```

# Choosing predictors for LDA

We are using these predictors as they make sense for grades:

HHPARN19X – number of parents in the household
EDCPUB – public vs other
SCCHOICE – school choice
EINTNET – internet at home
SCHLHRSWK – school hours per week
PARGRADEX – parent education
NUMSIBSX – number of siblings

```{r}
predictor_variables <- c(
  "HHPARN19X",  # number of parents in household
  "EDCPUB",     # public vs other school
  "SCCHOICE",   # school choice
  "EINTNET",    # internet at home
  "SCHLHRSWK",  # school hours per week
  "PARGRADEX",  # parent education
  "NUMSIBSX"    # number of siblings
)
```


```{r}
df_model <- df %>%
select(success, all_of(predictor_variables))
```

This step updates the dataset to keep only the response variable success along
with the seven predictors that will be used in the LDA model. These predictors
are for family structure, school type, school choice, internet access, school
hours, parent education, and number of siblings. A summary() output shows how 
each predictor is distributed across the data and confirms all seven variables
are stored as numeric values.

# Checking whether all variables are numeric

```{r}
df_model %>% 
  summarise(across(all_of(predictor_variables), ~ class(.)))
```

# Test-Train Data

```{r}
set.seed(123)

data_split <- initial_split(df_model, prop = 0.8, strata = success)
train_data <- training(data_split)
test_data  <- testing(data_split)
nrow(train_data)
nrow(test_data)
```

Here the data is split into an 80% training set and a 20% test set, preserving 
roughly the same proportion of low vs high `success` in each. 
The model, LDA, is fit to the training data and its performance is evaluated on the test data.

# Fitting the LDA Model

```{r}
lda_model <- discrim_linear() %>%
  set_mode("classification") %>%
  set_engine("MASS") %>%
  fit(
    success ~ HHPARN19X + EDCPUB + SCCHOICE +
      EINTNET + SCHLHRSWK + PARGRADEX + NUMSIBSX,
    data = train_data
  )

lda_model
```

Using the MASS engine, the LDA model classifies the students into either low or
high categories of academic success based on the seven predictors describing 
family structure, school setting, and learning conditions. The first line of the
output presents the prior probabilities: only 13.22% of the students fall into the
low-success group, while 86.78% of the students are in the high-success group;
hence, the dataset is strongly imbalanced. Group means show the average value of
each predictor in each category of success. For instance, students with low success
have values like HHPARN19X = 1.786, EINTNET = 3.872, SCHLHRSWK = 3.688, and 
PARGRADEX = 3.126, while students with high success have slightly higher averages,
such as EINTNET = 3.910, SCHLHRSWK = 3.776, and PARGRADEX = 3.676, which denote 
patterns of strong academic performance. 

Coefficients of the linear discriminant present the contribution of every predictor
to the separation of groups: negative coefficients, such as HHPARN19X (–0.705) and
SCCHOICE (–0.590), shift predictions toward the low-success category, while 
positive coefficients, such as EDCPUB (0.681), EINTNET (0.310), and PARGRADEX (0.467),
shift predictions toward high success. On the whole, these results express how 
predictors together finally form the discriminant function used in differentiating 
between low- and high-performing students.

# Getting predictions on test data 

```{r}
lda_test <- augment(lda_model, new_data = test_data)
head(lda_test)
```


```{r}
conf_mat(
  lda_test,
  truth   = success,
  estimate = .pred_class
)
```

```{r}
library(ggplot2)
library(dplyr)

cm <- conf_mat(lda_test, truth = success, estimate = .pred_class)

cm_df <- as.data.frame(cm$table)

ggplot(cm_df, aes(x = Prediction, y = Truth, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "white", size = 6) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Confusion Matrix Heatmap") +
  theme_minimal()
```




```{r}
metrics <- bind_rows(
  accuracy(lda_test, truth = success, estimate = .pred_class),
  precision(lda_test, truth = success, estimate = .pred_class, event_level = "second"),
  recall(lda_test, truth = success, estimate = .pred_class, event_level = "second"),
  f_meas(lda_test, truth = success, estimate = .pred_class, event_level = "second"),
  roc_auc(lda_test, truth = success, .pred_high)
)

metrics
```
Various performance metrics were used to test the performance of the LDA model against the test dataset.
The confusion matrix indicates that 1,614 students were correctly classified by the model,
leading to an accuracy of 86.36%. The model is very strong in classifying students in the high-success category;
the precision for this class is very high, with 86.77%, while recall stands at 99.45% and the F1 score is 92.67%.
The model strongly detects high-performing students. However, it performs poorly in detecting 
low-success students, mispredicting their class as being high for 246 out of the total. 
This imbalance is reflected in the ROC AUC value of 0.3277, which suggests poor separation of classes
while using probability scores. Overall, this model is good in predicting high-success cases but poor
in predicting the classes of low-success cases, as there is a considerable imbalance in the dataset.
```{r}
library(dplyr)
library(ggplot2)

# 1. Getting the underlying MASS::lda object from the parsnip model
lda_engine <- lda_model$fit

# 2. Predicting discriminant scores on the test data
lda_scores <- predict(lda_engine, newdata = test_data)

# 3. Add LD1 (first discriminant) as a new column to test_data
lda_values <- test_data %>%
  mutate(LD1 = lda_scores$x[, 1])

# 4. Plot LD1 distribution by success group
ggplot(lda_values, aes(x = LD1, fill = success)) +
  geom_density(alpha = 0.4) +
  labs(
    title = "LD1 Distribution by Success Group",
    x = "Linear Discriminant (LD1)",
    fill = "Success"
  ) +
  theme_minimal()

```
The LD1 plot shows how the LDA model separates the low-success and high-success students
using the first linear discriminant. If the model is strong, the two curves should have
very little overlap. In your plot, the red and blue curves representing low success and
high success, respectively, heavily overlap, which indicates that the model fails to
distinguish well between these two classes. While there is a slight shift of the 
high-success group to the right and the low-success group to the left, this separation
is weak. This confirms, once more, the poor discriminative power of the LDA model,
with its main causes lying in the high class imbalance of the dataset and the fact
that predictors do not strongly distinguish between low- and high-success students.
```{r}
library(ggplot2)

# ROC curve data
roc_data <- roc_curve(
  lda_test,
  truth = success,
  .pred_high
)

# Plot
ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(color = "darkgreen", size = 1.2) +
  geom_abline(linetype = "dashed", color = "red") +
  labs(
    title = "ROC Curve for LDA Model",
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)"
  ) +
  theme_minimal()

```

This ROC curve reflects that the LDA model performs slightly better than random guessing. 
The green curve lies near the diagonal reference line, which indicates that the model has
weak ability in distinguishing low-success students from high-success students. 
This is because the dataset is highly imbalanced, and the model tends to predict 
"high" most of the time. In summary, the ROC curve indicates poor discriminative power
and hence has limited usefulness for classification.


### Final Conclusion
Overall, the LDA model has very limited capability in telling low- from
high-success students. Overall, the LDA model does not turn out very well on the 
separation of the two Academic Success categories. Both the ROC curve and 
LD1 distribution show weak separation, and the confusion matrix confirms that the 
model is performing poorly in assigning cases to the groups. That would seem to imply
that the linear boundary given by LDA was inadequate for the structure of this dataset.
