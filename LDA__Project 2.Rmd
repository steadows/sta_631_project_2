---
title: "LDA_Project2"
author: "Sai Sreyaa Krishna Mallemala"
date: "2025-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggformula)
library(tidyverse)
library(tidymodels)
library(gridExtra)
library(readxl)
library(discrim)
library(yardstick)
```

# Data Loading and Preprocessing

```{r}
# Load and preprocess the data
df_2019 <- read_excel("pfi-data.xlsx", sheet = "curated 2019")
```

# Standardizing ALLGRADEX for 2019 data

```{r}
df_2019 <- df_2019 %>%
  mutate(
    ALLGRADEX_2019raw = ALLGRADEX,
    ALLGRADEX_std = case_when(
      ALLGRADEX %in% c(2, 3) ~ 0,                       # both K flavors → Kindergarten
      ALLGRADEX >= 4 & ALLGRADEX <= 15 ~ ALLGRADEX - 3, # 1st–12th → 1–12
      TRUE ~ NA_real_
    )
  )
```

# Filtering for high school students only

```{r}
df <- df_2019 %>%
  filter(ALLGRADEX_std >= 6 & ALLGRADEX_std <= 12)
```

# Handling target variable classes and missing values

```{r}
df <- df %>%
  # turn -1 and 5 into NA
  mutate(SEGRADES = na_if(SEGRADES, -1),
         SEGRADES = na_if(SEGRADES, 5)) %>%

  # drop rows where SEGRADES is missing
  filter(!is.na(SEGRADES)) %>%

  # create binary target: high vs low
  mutate(
    success = case_when(
      SEGRADES %in% c(1, 2) ~ "high",
      SEGRADES %in% c(3, 4) ~ "low"
    ),
    success = factor(success, levels = c("low", "high"))
  )%>%
  drop_na(success)

df %>% count(success)

```
```{r}
levels(df$success)
```

# Removing all unnecessary variables

```{r}
df <- df %>%
  select(-ZIPLOCL, -CDOBMM, -CDOBYY, -BASMID, -ALLGRADEX_std, -MOSTIMPT, -INTNUM, -ALLGRADEX_2019raw, -ALLGRADEX, -SEGRADES, - HHPARN19_BRD)
```

```{r}
glimpse(df)
```

# Choosing predictors for LDA

We are using these predictors as they make sense for grades:

HHPARN19X – number of parents in the household
EDCPUB – public vs other
SCCHOICE – school choice
EINTNET – internet at home
SCHLHRSWK – school hours per week
PARGRADEX – parent education
NUMSIBSX – number of siblings

```{r}
predictor_variables <- c(
  "HHPARN19X",  # number of parents in household
  "EDCPUB",     # public vs other school
  "SCCHOICE",   # school choice
  "EINTNET",    # internet at home
  "SCHLHRSWK",  # school hours per week
  "PARGRADEX",  # parent education
  "NUMSIBSX"    # number of siblings
)
```


```{r}
df_model <- df %>%
select(success, all_of(predictor_variables))
```

This step updates the dataset to keep only the response variable success along
with the seven predictors that will be used in the LDA model. These predictors
are for family structure, school type, school choice, internet access, school
hours, parent education, and number of siblings.

# Checking whether all variables are numeric

```{r}
df_model %>% 
  summarise(across(all_of(predictor_variables), ~ class(.)))
```

# Test-Train Data

```{r}
set.seed(123)

data_split <- initial_split(df_model, prop = 0.8, strata = success)
train_data <- training(data_split)
test_data  <- testing(data_split)
nrow(train_data)
nrow(test_data)
```

Stratified sampling based on the success variable is used to divide the data into
an 80% training set and a 20% test set, preserving the same proportion of low and
high success cases in both sets. This results in 7,472 observations for the training
set and 1,869 observations for the test set. We train the LDA model on the training
portion and evaluate the performance of the model using the test portion.

# Fitting the LDA Model

```{r}
lda_model <- discrim_linear() %>%
  set_mode("classification") %>%
  set_engine("MASS", prior = c(low = 0.5, high = 0.5)) %>%
  fit(
    success ~ HHPARN19X + EDCPUB + SCCHOICE +
      EINTNET + SCHLHRSWK + PARGRADEX + NUMSIBSX,
    data = train_data
  )

lda_model
```

The LDA model is estimated using the MASS engine with equal class priors of 0.5
for both low and high success. Setting equal priors means that both categories
are given equal importance during classification without regard for the imbalance
in their numbers within the dataset. The printed output reports these prior
probabilities first, followed by the group means for each predictor across the
low and high success categories. For instance, the averages of students in the
low-success group for the following variables were HHPARN19X = 1.786, EINTNET = 3.872,
SCHLHRSWK = 3.688, and PARGRADEX = 3.126, while those for students in the high-success
group were slightly higher, at EINTNET = 3.910, SCHLHRSWK = 3.776, and PARGRADEX = 3.676.
These represent general patterns that distinguish students who exhibit higher
performance academically.

The coefficients of the linear discriminant show the contribution that each of the
predictors makes toward separating the two groups along the LD1 dimension. 
The negative coefficients, for example, for HHPARN19X (–0.705) and SCCHOICE (–0.590),
pull predictions over to the low-success category, while positive coefficients, 
for instance, EDCPUB (0.681), EINTNET (0.310), SCHLHRSWK (0.128), and PARGRADEX (0.467),
pull predictions to the high-success category. These coefficients indicate the
direction and strength of each variable's influence in forming the discriminant
function that differentiates lowand high-success students.

# Getting predictions on test data 

```{r}
lda_test <- augment(lda_model, new_data = test_data)
head(lda_test)
```


```{r}
conf_mat(lda_test, truth = success, estimate = .pred_class)
```

```{r}
library(ggplot2)
library(dplyr)

cm <- conf_mat(lda_test, truth = success, estimate = .pred_class)

cm_df <- as.data.frame(cm$table)

ggplot(cm_df, aes(x = Prediction, y = Truth, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), color = "white", size = 6) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Confusion Matrix Heatmap") +
  theme_minimal()
```




```{r}
metrics <- bind_rows(
  accuracy(lda_test, truth = success, estimate = .pred_class),
  precision(lda_test, truth = success, estimate = .pred_class, event_level = "first"),
  recall(lda_test, truth = success, estimate = .pred_class, event_level = "first"),
  f_meas(lda_test, truth = success, estimate = .pred_class, event_level = "first"),
  roc_auc(lda_test, truth = success, .pred_low)
)

metrics
```
The confusion matrix from the model shows 1,622 students correctly classified out
of the total 1,869, giving an accuracy of 66.13%. Most correct predictions occur
in the high-success category, with 1,092 true high cases identified accurately.
However, performance is weaker for the low-success group. Out of the 247 actual
low-success students, only 103 were correctly classified, while 144 were misclassified
as high success. Such behavior is further emphasized by the value of the evaluation
metrics: for the low-success class, precision equals 0.21, recall equals 0.54,
while the F1-score is 0.31, showing limited ability to reliably detect low-success students.
Correspondingly, the ROC AUC has a value of 0.67, indicating a moderate
overall ranking ability but not strong separation between the two categories.
Overall, it performs much better on the identification of high-success students 
than on the identification of low-success students.

```{r}
library(dplyr)
library(ggplot2)

# 1. Getting the underlying MASS::lda object from the parsnip model
lda_engine <- lda_model$fit

# 2. Predicting discriminant scores on the test data
lda_scores <- predict(lda_engine, newdata = test_data)

# 3. Add LD1 (first discriminant) as a new column to test_data
lda_values <- test_data %>%
  mutate(LD1 = lda_scores$x[, 1])

# 4. Plot LD1 distribution by success group
ggplot(lda_values, aes(x = LD1, fill = success)) +
  geom_density(alpha = 0.4) +
  labs(
    title = "LD1 Distribution by Success Group",
    x = "Linear Discriminant (LD1)",
    fill = "Success"
  ) +
  theme_minimal()

```
The LD1 plot presents the way in which the LDA model separates students with
low academic success (grades 3-4) from those with high academic success (grades 1-2),
using the first linear discriminant. In a good model, the two density curves
should be clearly separated. However, this plot results in heavy overlapping,
which means predictors don't give a clear distinction between the LOW-success
and HIGH-success groups. While the HIGH-success group shifts slightly to the right
and the LOW-success group shifts slightly to the left in this plot, the separation
is weak. This confirms that the model has very poor discriminative power for detecting
LOW-success students, which is consistent with the evaluation metrics and the imbalance of the dataset.

```{r}
library(ggplot2)

# ROC curve data
roc_data <- roc_curve(lda_test, truth = success, .pred_low)


ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
geom_line(color="darkgreen", size=1.2) +
geom_abline(linetype="dashed", color="red") +
labs(title="ROC Curve for LOW Success Detection",
x="False Positive Rate",
y="True Positive Rate") +
theme_minimal()

```

The ROC curve indicates how well the LDA model is able to identify students who
have low academic success. The green curve lies just above the diagonal reference line,
suggesting that the model performs only slightly better than random guessing.
As the false positive rate increases, the true positive rate rises slowly,
meaning that the model needs to misclassify many high-success students in order
to detect low-success cases. This reflects that the predicted probabilities for
low and high success heavily overlap, providing the model with limited power to
distinguish between them. The model has an AUC of about 0.67, indicating weak
discriminative ability, thus it can't effectively tell low-success students from high-success students.


# Final Conclusion

The LDA model was developed with the key objective of identifying students at risk
of low academic success using the main demographic, school-related, and family-related
predictors. With respect to performance, when the model was tested on the test dataset,
the results show that while the model performs well in identifying high-success students,
it cannot reliably detect the low-success student target of interest. This is reflected
in the confusion matrix by the large proportion of low-success students identified as
high success, coupled with the low precision and F1-score of the low-success class.
Recall was moderate, meaning some of the low-success cases were captured by the model.
However, the overall predictive power remained weak. The ROC curve for low-success detection
did not extend far from the diagonal into the upper left corner, with an AUC of 0.67,
further confirming that there was only limited discriminative ability. 
Finally, the LD1 density plot showed substantial overlap between low- and high-success groups,
suggesting that the predictors did not divide the two categories sharply.
In summary, while these findings suggest that the model provides meaningful structure,
it is not sufficiently effective in identifying low-success students, which is our main objective.
It would require alternative models or additional predictors that improve the
detection of students with low success.